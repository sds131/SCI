{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easygraph as eg\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def make_graph(journal:str,time:list,country:list):\n",
    "    G=eg.Graph()\n",
    "    nodes=[]\n",
    "    nodes_attr=[]\n",
    "    edges=[]\n",
    "    edges_attr=[]\n",
    "    f=open('faculty-coauthors.csv','r')\n",
    "    next(f)\n",
    "    csv_reader=csv.reader(f)\n",
    "    for row in csv_reader:\n",
    "        if(int(row[6]) in time and str(row[7])==journal and row[2] in country and row[5] in country):\n",
    "            i=str(row[0])\n",
    "            i_affifiation=str(row[1])\n",
    "            i_country=str(row[2])\n",
    "            j=str(row[3])\n",
    "            j_affifiation=str(row[4])\n",
    "            j_country=str(row[5])\n",
    "            year=int(row[6])\n",
    "            area=str(row[7])\n",
    "\n",
    "            nodes.append(i)\n",
    "            temp1={}\n",
    "            temp1['affiliation']=i_affifiation\n",
    "            temp1['country']=i_country\n",
    "            nodes_attr.append(temp1)\n",
    "\n",
    "            nodes.append(j)\n",
    "            temp2={}\n",
    "            temp2['affiliation']=j_affifiation\n",
    "            temp2['country']=j_country\n",
    "            nodes_attr.append(temp2)\n",
    "\n",
    "            edges.append((i,j))\n",
    "            temp3={}\n",
    "            temp3['year']=year\n",
    "            temp3['area']=area\n",
    "            edges_attr.append(temp3)\n",
    "\n",
    "    G.add_nodes(nodes,nodes_attr)\n",
    "    G.add_edges(edges,edges_attr)\n",
    "    return G\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# socnet - 1999-2010\\ntime=[1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010]\\nG1=make_graph('socnet',time,'us')\\n# socnet - 2010-2021\\ntime=[2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021]\\nG2=make_graph('socnet',time,'us')\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw weight journal year\n",
    "# 14-21 18-21 99-21\n",
    "# tcss tsc socnet\n",
    "# country\n",
    "\n",
    "\n",
    "# tcss - 2014-2017\n",
    "time=[2014,2015,2016,2017]\n",
    "G1=make_graph('tcss',time,'cn')\n",
    "# tcss - 2018-2021\n",
    "time=[2018,2019,2020,2021]\n",
    "G2=make_graph('tcss',time,'cn')\n",
    "\"\"\"\n",
    "# tcss - 2014-2017\n",
    "time=[2014,2015,2016,2017]\n",
    "G1=make_graph('tcss',time,'us')\n",
    "# tcss - 2018-2021\n",
    "time=[2018,2019,2020,2021]\n",
    "G2=make_graph('tcss',time,'us')\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# tsc - 2018-2019\n",
    "time=[2018,2019]\n",
    "G1=make_graph('tsc',time)\n",
    "# tsc - 2020-2021\n",
    "time=[2020,2021]\n",
    "G2=make_graph('tsc',time)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# socnet - 1999-2010\n",
    "time=[1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010]\n",
    "G1=make_graph('socnet',time,'us')\n",
    "# socnet - 2010-2021\n",
    "time=[2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021]\n",
    "G2=make_graph('socnet',time,'us')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 48\n"
     ]
    }
   ],
   "source": [
    "print(len(G1),G1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405 748\n"
     ]
    }
   ],
   "source": [
    "print(len(G2),G2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def degree_cdf(G1,G2):\n",
    "    D1=G1.degree()\n",
    "    D2=G2.degree()\n",
    "\n",
    "    data=[]\n",
    "    for i in D1:\n",
    "        data.append(D1[i])\n",
    "    for i in G1.nodes:\n",
    "        if i not in D1:\n",
    "            data.append(0)\n",
    "    test=pd.DataFrame(data)\n",
    "    test.to_csv('/users/sds/downloads/degree1.csv')\n",
    "\n",
    "    data=[]\n",
    "    for i in D2:\n",
    "        data.append(D2[i])\n",
    "    for i in G2.nodes:\n",
    "        if i not in D2:\n",
    "            data.append(0)\n",
    "    test=pd.DataFrame(data)\n",
    "    test.to_csv('/users/sds/downloads/degree2.csv')\n",
    "\n",
    "degree_cdf(G1,G2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "Gn1=nx.Graph()\n",
    "for i in G1.edges:\n",
    "    (u,v,t)=i\n",
    "    Gn1.add_edge(u,v)\n",
    "\n",
    "Gn2=nx.Graph()\n",
    "for i in G2.edges:\n",
    "    (u,v,t)=i\n",
    "    Gn2.add_edge(u,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cc_cdf(Gn1,Gn2):\n",
    "    C1=[]\n",
    "    for i in Gn1.nodes:\n",
    "        k=nx.clustering(Gn1,i)\n",
    "        C1.append(k)\n",
    "    test=pd.DataFrame(C1)\n",
    "    test.to_csv('/users/sds/downloads/clustering_coefficient1.csv')\n",
    "\n",
    "    C2=[]\n",
    "    for i in Gn2.nodes:\n",
    "        k=nx.clustering(Gn2,i)\n",
    "        C2.append(k)  \n",
    "    test=pd.DataFrame(C2)\n",
    "    test.to_csv('/users/sds/downloads/clustering_coefficient2.csv')\n",
    "\n",
    "cc_cdf(Gn1,Gn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr_cdf(Gn1,Gn2):\n",
    "    P1=nx.pagerank(Gn1,alpha=0.85)\n",
    "    data=[]\n",
    "    for i in P1:\n",
    "        data.append(P1[i])\n",
    "    test=pd.DataFrame(data)\n",
    "    test.to_csv('/users/sds/downloads/pagerank1.csv')\n",
    "\n",
    "    P2=nx.pagerank(Gn2,alpha=0.85)\n",
    "    data=[]\n",
    "    for i in P2:\n",
    "        data.append(P2[i])\n",
    "    test=pd.DataFrame(data)\n",
    "    test.to_csv('/users/sds/downloads/pagerank2.csv')    \n",
    "\n",
    "pr_cdf(Gn1,Gn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cc_cdf(Gn1,Gn2):\n",
    "    CC1=[len(c) for c in sorted(nx.connected_components(Gn1), key=len, reverse=True)]\n",
    "    cc1={\n",
    "        'size_of_cc':[]\n",
    "    }\n",
    "    for i in CC1:\n",
    "        cc1['size_of_cc'].append(i)\n",
    "    test=pd.DataFrame(cc1)\n",
    "    test.to_csv('/users/sds/downloads/connected_components1.csv')\n",
    "\n",
    "    CC2=[len(c) for c in sorted(nx.connected_components(Gn2), key=len, reverse=True)]\n",
    "    cc2={\n",
    "        'size_of_cc':[]\n",
    "    }\n",
    "    for i in CC2:\n",
    "        cc2['size_of_cc'].append(i)\n",
    "    test=pd.DataFrame(cc2)\n",
    "    test.to_csv('/users/sds/downloads/connected_components2.csv')\n",
    "\n",
    "cc_cdf(Gn1,Gn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pl_cdf(Gn1,Gn2):\n",
    "    LCC1=nx.Graph()\n",
    "    c=max(nx.connected_components(Gn1),key=len)\n",
    "    c=list(c)\n",
    "    LCC1=Gn1.subgraph(c).copy()\n",
    "\n",
    "    pl1={}\n",
    "    for i in LCC1.nodes:\n",
    "        for j in LCC1.nodes:\n",
    "            t=nx.shortest_path_length(LCC1,i,j)\n",
    "            if t!=0:\n",
    "                if t not in pl1:\n",
    "                    pl1[t]=1\n",
    "                else:\n",
    "                    pl1[t]+=1\n",
    "\n",
    "    LCC2=nx.Graph()\n",
    "    c=max(nx.connected_components(Gn2),key=len)\n",
    "    c=list(c)\n",
    "    LCC2=Gn2.subgraph(c).copy()\n",
    "\n",
    "    pl2={}\n",
    "    for i in LCC2.nodes:\n",
    "        for j in LCC2.nodes:\n",
    "            t=nx.shortest_path_length(LCC2,i,j)\n",
    "            if t!=0:\n",
    "                if t not in pl2:\n",
    "                    pl2[t]=1\n",
    "                else:\n",
    "                    pl2[t]+=1\n",
    "\n",
    "    PL1={\n",
    "        'path_length':[],\n",
    "        'num_of_path_length':[]\n",
    "    }\n",
    "    for i in pl1:\n",
    "        PL1['path_length'].append(i)\n",
    "        PL1['num_of_path_length'].append(pl1[i])\n",
    "    test=pd.DataFrame(PL1)\n",
    "    test.to_csv('/users/sds/downloads/path_length1.csv')\n",
    "\n",
    "    PL2={\n",
    "        'path_length':[],\n",
    "        'num_of_path_length':[]\n",
    "    }\n",
    "    for i in pl2:\n",
    "        PL2['path_length'].append(i)\n",
    "        PL2['num_of_path_length'].append(pl2[i])\n",
    "    test=pd.DataFrame(PL2)\n",
    "    test.to_csv('/users/sds/downloads/path_length2.csv')\n",
    "    \n",
    "pl_cdf(Gn1,Gn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def burt(G):\n",
    "    constraint=eg.constraint(G)\n",
    "    \n",
    "    data={\n",
    "        'constraint':[]\n",
    "    }\n",
    "\n",
    "    for i in G:\n",
    "        data['constraint'].append(float(constraint[i]))\n",
    "        \n",
    "    return pd.DataFrame(data)\n",
    "    \n",
    "burt(G1).to_csv('/users/sds/downloads/constraint1.csv')\n",
    "burt(G2).to_csv('/users/sds/downloads/constraint2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main country bar\n",
    "\n",
    "# degree\n",
    "# betweenness centrality\n",
    "# effective size\n",
    "# efficiency\n",
    "# constraint\n",
    "# hierarchy\n",
    "# clustering coefficient\n",
    "# page rank\n",
    "# top10\n",
    "# page length\n",
    "# robustness\n",
    "\n",
    "# country 国家内\n",
    "# country1 and country2 国家间"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
