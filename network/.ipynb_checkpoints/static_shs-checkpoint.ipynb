{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easygraph as eg\n",
    "import csv\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import  pyplot\n",
    "import warnings\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, roc_curve, recall_score, f1_score, roc_auc_score, accuracy_score\n",
    "\n",
    "def make_graph(filepath:str):\n",
    "    G=eg.Graph()\n",
    "    nodes=[]\n",
    "    nodes_attr=[]\n",
    "    edges=[]\n",
    "    edges_attr=[]\n",
    "    f=open(filepath,'r')\n",
    "    next(f)\n",
    "    csv_reader=csv.reader(f)\n",
    "    for row in csv_reader:\n",
    "        i=str(row[0])\n",
    "        i_affifiation=str(row[1])\n",
    "        i_country=str(row[2])\n",
    "        j=str(row[3])\n",
    "        j_affifiation=str(row[4])\n",
    "        j_country=str(row[5])\n",
    "        year=int(row[6])\n",
    "        area=str(row[7])\n",
    "\n",
    "        nodes.append(i)\n",
    "        temp1={}\n",
    "        temp1['affiliation']=i_affifiation\n",
    "        temp1['country']=i_country\n",
    "        nodes_attr.append(temp1)\n",
    "\n",
    "        nodes.append(j)\n",
    "        temp2={}\n",
    "        temp2['affiliation']=j_affifiation\n",
    "        temp2['country']=j_country\n",
    "        nodes_attr.append(temp2)\n",
    "\n",
    "        edges.append((i,j))\n",
    "        temp3={}\n",
    "        temp3['year']=year\n",
    "        temp3['area']=area\n",
    "        edges_attr.append(temp3)\n",
    "\n",
    "    G.add_nodes(nodes,nodes_attr)\n",
    "    G.add_edges(edges,edges_attr)\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author\n",
    "G1=make_graph('faculty-coauthors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHS=sorted(eg.constraint(G1).items(), key=lambda d: d[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "con=eg.constraint(G1)\n",
    "con=sorted(con.items(), key=lambda d: d[1])\n",
    "\n",
    "\n",
    "SHS1=[]\n",
    "nonSHS1=[]\n",
    "\n",
    "kk=int(len(G1)*0.05)\n",
    "k=0\n",
    "for i in con:\n",
    "    if k<kk:\n",
    "        SHS1.append(i[0])\n",
    "        k+=1\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "random.seed(0)\n",
    "while len(nonSHS1)<kk:\n",
    "    t=random.sample(con, 1)\n",
    "    if t[0][0] not in SHS1 and t[0][0] not in nonSHS1:\n",
    "        nonSHS1.append(t[0][0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# A. Suruliandi\tManonmaniam Sundaranar University\ttcss\t2\t0.58333\t2021\n",
    "f1=open(\"generated-author-info.csv\",'r')\n",
    "f2=open(\"country-info2.csv\",\"r\")\n",
    "next(f1)\n",
    "next(f2)\n",
    "csv_reader1=csv.reader(f1)\n",
    "csv_reader2=csv.reader(f2)\n",
    "List={}\n",
    "country_list={}\n",
    "for row in csv_reader2:\n",
    "    country_list[row[0]]=row[2]\n",
    "for row in csv_reader1:\n",
    "    if row[0] in SHS1 or row[0] in nonSHS1:\n",
    "        if row[0] not in List:\n",
    "            List[row[0]]={}\n",
    "            List[row[0]]['country']=country_list[row[1]]\n",
    "            List[row[0]]['university']=row[1]\n",
    "            List[row[0]]['journal']=[]\n",
    "            List[row[0]]['journal'].append(row[2])\n",
    "            List[row[0]]['paper']=float(row[3])\n",
    "            List[row[0]]['count']=[]\n",
    "            List[row[0]]['count'].append(float(row[4]))\n",
    "            List[row[0]]['year']=[]\n",
    "            List[row[0]]['year'].append(int(row[5]))\n",
    "            if row[0] in SHS1:\n",
    "                List[row[0]]['label']=1\n",
    "            else:\n",
    "                List[row[0]]['label']=0\n",
    "        else:\n",
    "            if row[2] not in List[row[0]]['journal']:\n",
    "                List[row[0]]['journal'].append(row[2])\n",
    "            List[row[0]]['paper']+=float(row[3])\n",
    "            List[row[0]]['count'].append(float(row[4]))\n",
    "            List[row[0]]['year'].append(int(row[5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={\n",
    "    'country':[],\n",
    "    'university':[],\n",
    "    'journal':[],\n",
    "    'paper':[],\n",
    "    'count':[],\n",
    "    'year':[],\n",
    "    'label':[]\n",
    "}\n",
    "for i in List:\n",
    "    data['country'].append(List[i]['country'])\n",
    "    data['university'].append(List[i]['university'])\n",
    "    data['journal'].append(len(List[i]['journal']))\n",
    "    data['paper'].append(List[i]['paper'])\n",
    "    data['count'].append(np.mean(List[i]['count']))\n",
    "    data['year'].append(len(List[i]['year'])*2021-sum(List[i]['year']))\n",
    "    data['label'].append(List[i]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "data['country'] = label_encoder.fit_transform(data['country'])\n",
    "data['university'] = label_encoder.fit_transform(data['university'])\n",
    "data=pd.DataFrame(data)\n",
    "data = pd.get_dummies(data)\n",
    "data_x = data.drop('label',axis = 1)\n",
    "data_y = data['label']\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(data_x,data_y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "parameters_grid_XGB = {\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'n_estimators': [10, 50, 100], \n",
    "    'max_depth': [4,6,8], \n",
    "    'min_child_weight':[1],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree':[0.8], \n",
    "    'gamma':[0,2,4],\n",
    "    \n",
    "    'booster': ['gbtree'],\n",
    "    'num_class':[2],\n",
    "    'eval_metric':[\"auc\"],\n",
    "    'objective':['multi:softprob'],\n",
    "    'seed':[0],\n",
    "    'use_label_encoder':['False']\n",
    "}\n",
    "XGB = XGBClassifier()\n",
    "grid = GridSearchCV(XGB, parameters_grid_XGB, cv=5, scoring='precision')\n",
    "grid.fit(Xtrain, Ytrain)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(grid.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "bclf = grid.best_estimator_\n",
    "bclf.fit(Xtrain, Ytrain)\n",
    "y_true = Ytest\n",
    "y_pred = bclf.predict(Xtest)\n",
    "y_pred_pro = bclf.predict_proba(Xtest)\n",
    "y_scores = pd.DataFrame(y_pred_pro, columns=bclf.classes_.tolist())[1].values\n",
    "print(classification_report(y_true, y_pred))\n",
    "auc_value = roc_auc_score(y_true, y_scores)\n",
    "print(\"auc_value:\")\n",
    "print(auc_value)\n",
    "\n",
    "plot_importance(bclf,title='Feature importance ranking', xlabel='score', ylabel='feature')\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
